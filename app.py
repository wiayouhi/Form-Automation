import time, random, threading, requests
import json
from queue import Queue
from flask import Flask, render_template, request, Response, jsonify
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs
from requests.exceptions import RequestException

app = Flask(__name__)

# Global resources for thread management
count_lock = threading.Lock()
job_queue = Queue()
log_queue = Queue()
stop_event = threading.Event()

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
SUCCESS_COUNT = [0]
FAIL_COUNT = [0]
TOTAL_JOBS = 0

# =========================
# Utils & Core Logic
# =========================

def fetch_fbzx(view_url):
    """‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ fbzx ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ viewform"""
    try:
        r = requests.get(view_url, timeout=5)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        tag = soup.find("input", {"name": "fbzx"})
        return tag["value"] if tag else None
    except RequestException as e:
        # log_queue.put(f"‚ùå ERROR: Cannot fetch fbzx - {e}")
        return None

def submission_worker(post_url, fbzx, page_history, entries_map, mode, delay):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Worker ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Thread ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏ü‡∏≠‡∏£‡πå‡∏°"""
    while not job_queue.empty() and not stop_event.is_set():
        try:
            # ‡∏î‡∏∂‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≤‡∏Å Queue
            idx = job_queue.get(timeout=1)
        except:
            continue # Queue empty

        time.sleep(delay) # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Payload
        payload = {
            "fvv": "1", 
            "fbzx": fbzx, 
            "pageHistory": page_history,
            "draftResponse": []
        }
        
        for eid, val in entries_map.items():
            options = [v.strip() for v in val.split(',') if v.strip()]
            
            # ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: Random ‡∏´‡∏£‡∏∑‡∏≠ Sequential
            if mode == 'R':
                answer = random.choice(options)
            else:
                # ‡πÉ‡∏ä‡πâ idx ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö Sequential
                answer = options[idx % len(options)] 
                
            payload[eid] = answer

        # 2. ‡∏™‡πà‡∏á Request
        try:
            r = requests.post(post_url, data=payload, timeout=10)
            if r.status_code in (200, 302, 303):
                status = f"‚úÖ SUCCESS (HTTP {r.status_code})"
                with count_lock: SUCCESS_COUNT[0] += 1
            else:
                status = f"‚ùå FAIL (HTTP {r.status_code})"
                with count_lock: FAIL_COUNT[0] += 1
        except RequestException as e:
            status = f"‚ö†Ô∏è ERROR ({type(e).__name__})"
            with count_lock: FAIL_COUNT[0] += 1
        
        # ‡∏™‡πà‡∏á Log ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà Log Queue
        log_queue.put(f"[{time.strftime('%H:%M:%S')}] #{idx+1} | {status} | Total: {SUCCESS_COUNT[0]}/{TOTAL_JOBS}")
        job_queue.task_done()

# =========================
# Flask Routes
# =========================

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/parse-url', methods=['POST'])
def parse_url():
    url = request.json.get('url', '')
    parsed = urlparse(url)
    params = parse_qs(parsed.query)
    entries = {k: v[0] for k, v in params.items() if k.startswith("entry.")}
    return jsonify({"entries": entries})

@app.route('/api/stream')
def stream():
    """API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡πâ‡∏ß‡∏¢ Thread ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á Log (SSE)"""
    global job_queue, SUCCESS_COUNT, FAIL_COUNT, TOTAL_JOBS
    
    # Reset ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÅ‡∏•‡∏∞ Queue ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°
    job_queue = Queue()
    log_queue.queue.clear() # Clear log queue
    SUCCESS_COUNT[0] = 0
    FAIL_COUNT[0] = 0
    stop_event.clear()

    # 1. ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ Configuration
    form_url = request.args.get('url')
    TOTAL_JOBS = int(request.args.get('total', 1))
    bots = int(request.args.get('bots', 1))
    delay = float(request.args.get('delay', 0.5))
    mode = request.args.get('mode', 'R')
    num_pages = int(request.args.get('pages', 1))
    
    entries_raw = request.args.get('entries')
    entries_map = json.loads(entries_raw)

    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° URL ‡πÅ‡∏•‡∏∞ fbzx
    base = form_url.split("?")[0].rstrip("/")
    if base.endswith(("viewform", "formResponse")):
        base = base.rsplit("/", 1)[0]
    post_url = f"{base}/formResponse"
    view_url = f"{base}/viewform"
    
    fbzx = fetch_fbzx(view_url)
    
    if not fbzx:
        def error_generator():
            yield "data: ‚ùå ERROR: Cannot fetch fbzx token or URL is invalid.\n\n"
        return Response(error_generator(), mimetype='text/event-stream')

    # 3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì pageHistory
    page_history = ",".join(str(i) for i in range(num_pages))
    
    # 4. Populate Job Queue
    for i in range(TOTAL_JOBS):
        job_queue.put(i)
    
    # 5. Start Worker Threads
    threads = []
    for _ in range(bots):
        thread = threading.Thread(
            target=submission_worker,
            args=(post_url, fbzx, page_history, entries_map, mode, delay)
        )
        threads.append(thread)
        thread.start()

    # 6. Generator Function (Main thread for SSE)
    def process_generator():
        start_time = time.time()
        
        yield f"data: üöÄ Starting process with {TOTAL_JOBS} submissions, {bots} bots, {num_pages} sections (History: {page_history}).\n\n"
        
        while SUCCESS_COUNT[0] + FAIL_COUNT[0] < TOTAL_JOBS:
            if not log_queue.empty():
                log_msg = log_queue.get()
                yield f"data: {log_msg}\n\n"
            
            # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πà‡∏ß‡∏á Main thread ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            time.sleep(0.05) 

        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ Log ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á (LogQueue ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢)
        while not log_queue.empty():
            log_msg = log_queue.get()
            yield f"data: {log_msg}\n\n"

        duration = time.time() - start_time
        yield f"data: üèÅ FINISHED! Total Time: {duration:.2f}s | Success: {SUCCESS_COUNT[0]} | Fail: {FAIL_COUNT[0]}\n\n"

        # Cleanup threads
        job_queue.join() 
        for t in threads:
            if t.is_alive():
                 t.join(timeout=0.1)


    return Response(process_generator(), mimetype='text/event-stream')


if __name__ == '__main__':
    app.run(debug=True, threaded=True)